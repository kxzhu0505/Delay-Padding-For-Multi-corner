import math
import numpy as np
import networkx as nx
from typing import Tuple
from typing import Dict
# from core.bf_solver import bellman_ford_solver
from core.lp_solver import solve_subproblem_lp
from core.utils import initialize_y_k, initialize_y_shared, initialize_lambda_k, check_convergence

def run_dual_delay_padding(corner_graphs: Dict[str, 'nx.DiGraph'], T_CLK: float, max_iter: int = 200, rho: float = 1):
    # Step 1: åˆå§‹åŒ–æ¯ä¸ªè§’çš„ y^(k)
    # setup analysisï¼ˆlongest delay pathï¼‰
    y_k_setup = initialize_y_k(corner_graphs, mode="setup")
    
    # hold analysisï¼ˆshortest delay pathï¼‰
    y_k_hold = initialize_y_k(corner_graphs, mode="hold")
    # print(f"y_k_setup: {y_k_setup}")
    # print(f"y_k_hold: {y_k_hold}")

    # # Step 2: åˆå§‹åŒ–å…±äº« y
    y_shared_setup = initialize_y_shared(y_k_setup)
    y_shared_hold = initialize_y_shared(y_k_hold)

    # print(f"y_shared_setup: {y_shared_setup}")
    # print(f"y_shared_hold: {y_shared_hold}")

    # # Step 3: åˆå§‹åŒ– Î»_k
    lambda_k_setup = initialize_lambda_k(y_k_setup)
    lambda_k_hold = initialize_lambda_k(y_k_hold)

    # print(f"lambda_k_setup: {lambda_k_setup}")
    # print(f"lambda_k_hold: {lambda_k_hold}")

    T_LOW = 0.1
    T_HIGH = T_CLK
    for iteration in range(max_iter):
        T_MID = (T_LOW + T_HIGH) / 2

        print(f"\nğŸ” Iteration {iteration}: Trying T_CLK = {T_MID:.4f}")
        # Step 4: è¿›å…¥ä¸»è¿­ä»£
    
        # === Step 1: setup æ¨¡å¼ä¸‹çš„ delay padding æ±‚è§£ ===
        print("ğŸ”§ Solving for SETUP mode...")
        final_y_k_setup, final_y_shared_setup = dual_loop_solver_path_based(
            y_k=y_k_setup,
            y_shared=y_shared_setup,
            lambda_k=lambda_k_setup,
            corner_graphs=corner_graphs,
            T_CLK=T_CLK,
            mode="setup"
        )

        # # === Step 2: hold æ¨¡å¼ä¸‹çš„ delay padding æ±‚è§£ ===
        print("ğŸ”§ Solving for HOLD mode...")
        final_y_k_hold, final_y_shared_hold = dual_loop_solver_path_based(
            y_k=y_k_hold,
            y_shared=y_shared_hold,
            lambda_k=lambda_k_hold,
            corner_graphs=corner_graphs,
            T_CLK=T_CLK,
            mode="hold"
        )

        # å»¶è¿Ÿå¡«å……
        setup_delay_patch = implement_delay_padding(final_y_shared_setup, corner_graphs["ss_asap7"], T_CLK)
        hold_delay_patch = implement_delay_padding(final_y_shared_hold, corner_graphs["ff_asap7"], T_CLK)

        # éªŒè¯å»¶è¿Ÿå¡«å……
        valid_setup = verify_patched_timing(final_y_shared_setup, corner_graphs["ss_asap7"], setup_delay_patch, T_CLK)
        valid_hold = verify_patched_timing(final_y_shared_hold, corner_graphs["ff_asap7"], hold_delay_patch, T_CLK)

        if valid_setup and valid_hold:
            T_HIGH = T_MID
        else:
            T_LOW = T_MID
        
        if abs(T_HIGH - T_LOW) < 1e-3:
            print(f"\nâœ… Converged. Returning T_CLK = {T_HIGH:.4f}")
            return T_HIGH

    print(f"\nâš ï¸ Did not converge. Returning conservative T_CLK = {T_HIGH:.4f}")
    return T_HIGH

def dual_loop_solver_path_based(
    y_k: Dict[str, Dict[Tuple[str, str], float]],
    y_shared: Dict[Tuple[str, str], float],
    lambda_k: Dict[str, Dict[Tuple[str, str], float]],
    corner_graphs: Dict[str, any],
    T_CLK: float,
    mode: str = "setup",
    max_iter: int = 50,
    rho: float = 1.0,
    tol: float = 1e-3
):
    """
    Dual decomposition solver (path-based LP version).
    """
    
    for it in range(max_iter):
        print(f"\nğŸ” Iteration {it} [{mode}]")

        # 1. solve subproblem per corner
        for corner in y_k:
            try:
                y_k[corner] = solve_subproblem_lp(T_CLK, corner, y_shared, lambda_k, corner_graphs[corner], mode=mode)
            except RuntimeError as e:
                print(str(e))
                continue

        # 2. update shared y
        all_edges = set(edge for ck in y_k.values() for edge in ck)
        new_y_shared = {
            edge: sum(y_k[c][edge] for c in y_k if edge in y_k[c]) / len([c for c in y_k if edge in y_k[c]])
            for edge in all_edges
        }

        # 3. check convergence
        # diff = max(abs(new_y_shared[e] - y_shared[e]) for e in new_y_shared if e in y_shared)
        # print(f"ğŸ” Max change in y_shared: {diff:.4f}")
        # if diff < tol:
        #     print("âœ… Converged.")
        #     return y_k, new_y_shared
        if check_convergence(y_k, new_y_shared, y_shared):
            return y_k, new_y_shared
        

        y_shared = new_y_shared

        # method 1
        # 4. update lambda_k
        avg_deviation = {}
        for edge in y_shared:
            deviations = [y_k[corner][edge] - y_shared[edge] for corner in y_k]
            avg_deviation[edge] = sum(map(abs, deviations)) / len(deviations)
   
        for corner in y_k:
            for edge in y_k[corner]:
                # æ ¹æ®åå·®å¤§å°åŠ¨æ€è°ƒæ•´rho
                adaptive_rho = rho * (1.0 / (1.0 + avg_deviation[edge]))
                delta = y_k[corner][edge] - y_shared[edge]
                lambda_k[corner][edge] += adaptive_rho * delta
        # 4. update lambda_k
        # method 2
        # for corner in y_k:
        #     for edge in y_k[corner]:
        #         lambda_k[corner][edge] += rho * (y_k[corner][edge] - y_shared[edge])
        
        #method 3
        # for corner in y_k:
        #     for edge in y_k[corner]:
        #         # å½’ä¸€åŒ–çš„æ›´æ–°
        #         delta = (y_k[corner][edge] - y_shared[edge]) / max(abs(y_shared[edge]), 1.0)
        #         lambda_k[corner][edge] += rho * delta


    print("âš ï¸ Reached max iterations without convergence.")
    return y_k, y_shared

def check_convergence(y_k, new_y_shared, y_shared, tol=1e-3, rel_tol=1e-2):
    # 1. æ£€æŸ¥y_sharedçš„å˜åŒ–
    abs_diff = max(abs(new_y_shared[e] - y_shared[e]) for e in new_y_shared if e in y_shared)
    rel_diff = max(
        abs(new_y_shared[e] - y_shared[e]) / max(abs(y_shared[e]), 1.0)
        for e in new_y_shared if e in y_shared
    )
    
    # 2. æ£€æŸ¥æ‰€æœ‰corneræ˜¯å¦éƒ½æ¥è¿‘y_shared
    corner_diff = max(
        abs(y_k[corner][edge] - new_y_shared[edge]) / max(abs(new_y_shared[edge]), 1.0)
        for corner in y_k
        for edge in y_k[corner]
    )
    
    # æ‰“å°è¯¦ç»†çš„æ”¶æ•›ä¿¡æ¯
    print(f"ğŸ” Absolute change in y_shared: {abs_diff:.4f}")
    print(f"ğŸ” Relative change in y_shared: {rel_diff:.4f}")
    print(f"ğŸ” Max corner deviation: {corner_diff:.4f}")
    
    # åŒæ—¶æ»¡è¶³ä¸‰ä¸ªæ¡ä»¶æ‰è®¤ä¸ºæ”¶æ•›
    is_converged = (abs_diff < tol) and (rel_diff < rel_tol) and (corner_diff <= 0.1)
    
    if is_converged:
        print("âœ… Converged.")
    
    return is_converged


def implement_delay_padding(y_shared: Dict[Tuple[str, str], float], 
                            graph: nx.DiGraph,
                            T_CLK: float,
                            tol: float = 1e-3):
    """
    æ ¹æ®å…±äº« delayï¼ˆy_sharedï¼‰ä¸æ—¶é’Ÿå‘¨æœŸï¼Œå¯¹å›¾ä¸­çš„è¾¹æ’å…¥å¿…è¦çš„ delay ä»¥æ»¡è¶³ setup/holdã€‚
    """
    delay_patch = {}  # {(u, v): delay_to_add}

    for u, v in graph.edges():
        y = y_shared.get((u, v), None)
        if y is None:
            continue  # skip if no y_shared for this edge

        # Get setup & hold library constraints
        setup_info = graph[u][v].get('setup_delay', {})
        hold_info  = graph[u][v].get('hold_delay', {})
        setup_time = setup_info.get('library_time', None)
        hold_time  = hold_info.get('library_time', None)

        if setup_time is None or hold_time is None:
            continue  # skip if missing info

        required_max = T_CLK + setup_time
        required_min = max(hold_time, 0.0)

        padding = 0.0

        # Setup violation: arrival too late
        if y > required_max:
            pad = y - required_max
            print(f"âš ï¸ Setup violation on edge {u}->{v}: arrival={y:.2f} > {required_max:.2f}, pad={pad:.2f}")
            padding = max(padding, pad)

        # Hold violation: arrival too early
        if y < required_min:
            pad = required_min - y
            print(f"âš ï¸ Hold violation on edge {u}->{v}: arrival={y:.2f} < {required_min:.2f}, pad={pad:.2f}")
            padding = max(padding, pad)

        if padding > 0:
            delay_patch[(u, v)] = padding

    return delay_patch

def verify_patched_timing(y_shared: Dict[Tuple[str, str], float],
                          graph: nx.DiGraph,
                          delay_patch: Dict[Tuple[str, str], float],
                          T_CLK: float,
                          tol: float = 1e-3) -> bool:
    """
    éªŒè¯åº”ç”¨ delay patch åï¼Œæ‰€æœ‰ setup/hold çº¦æŸæ˜¯å¦æ»¡è¶³
    """
    all_passed = True

    for u, v in graph.edges():
        y = y_shared.get((u, v), None)
        if y is None:
            continue

        patch = delay_patch.get((u, v), 0.0)
        y_patched = y - patch
        # æ³¨æ„è¿™é‡Œæ˜¯ + è¿˜æ˜¯ -

        # è·å– library çº¦æŸ
        setup_time = graph[u][v]['setup_delay'].get('library_time', None)
        hold_time  = graph[u][v]['hold_delay'].get('library_time', None)
        if setup_time is None or hold_time is None:
            continue

        required_max = T_CLK + setup_time
        required_min = hold_time

        # æ£€æŸ¥ setup violation
        if y_patched > required_max:
            print(f"âŒ Setup FAIL: {u}->{v}, patched_y = {y_patched:.2f} > {required_max:.2f}")
            all_passed = False

        # æ£€æŸ¥ hold violation
        if y_patched < required_min:
            print(f"âŒ Hold FAIL: {u}->{v}, patched_y = {y_patched:.2f} < {required_min:.2f}")
            all_passed = False

    if all_passed:
        print("âœ… All timing constraints met after delay padding.")
    else:
        print("âŒ Timing violations remain after delay padding.")
    
    return all_passed

